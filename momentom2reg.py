# -*- coding: utf-8 -*-
"""MomentoM2Reg

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JwiyoKg9YMwAD8zwWw9xUnPHLPqx_25M
"""

#Importación de las librerías
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, f1_score
from sklearn.model_selection import train_test_split
#Importar el dataset y limpiarlo
df = pd.read_csv("Calorias FastF.csv")
df = df.apply(pd.to_numeric, errors='coerce')
df['Calories'] = np.where(df['Calories'] > 219, 'Si', "No")
df=df.dropna()
y = np.array(df['Saturated Fat\n(g)']) # Cantidad de Saturated Fatd Fat en g en el alimento
x = np.array(df['Calories from\nFat']) # 'Cantidad de Calories from\nFat en mg en el alimento
Cal= np.array(df['Calories']) # Indica si el Aliemnto tiene más o menos de 220 CaloriasSaturated FatSaturated Fat
# Dividir el dataset en conjuntos de entrenamiento y prueba (70% entrenamiento, 30% prueba)
# x: variable independiente ('Calories from Fat')
# y: variable dependiente ('Saturated Fat')
# Cal: variable de clasificación ('Calorías') indicando si tiene más o menos de 220 calorías
x_train, x_test, y_train, y_test, Cal_train, Cal_test = train_test_split(x, y, Cal, test_size=0.3, random_state=42)

# Inicialización de los parámetros del modelo
m = 0  # Pendiente inicial de la línea de regresión
b = 0  # Intercepto inicial de la línea de regresión
alpha = 1e-90  # Tasa de aprendizaje para el algoritmo de descenso de gradiente
epochs = 10000  # Número máximo de iteraciones
tolerance = 1e-6  # Tolerancia para la convergencia (criterio de parada)
n_train = len(x_train)  # Número de puntos de datos en el conjunto de entrenamiento

# Algoritmo de descenso de gradiente
for epoch in range(epochs):
    hxi = m * x_train + b  # Calcular las predicciones usando la fórmula de la línea de regresión
    error = hxi - y_train  # Calcular los errores entre las predicciones y los valores reales de 'y'
    costo_m = (1/n_train) * sum(error * x_train)  # Calcular el gradiente para ajustar 'm'
    costo_b = (1/n_train) * sum(error)  # Calcular el gradiente para ajustar 'b'
    m -= alpha * costo_m  # Actualizar 'm' utilizando el gradiente y la tasa de aprendizaje 'alpha'
    b -= alpha * costo_b  # Actualizar 'b' utilizando el gradiente y la tasa de aprendizaje 'alpha'

    # Verificar si el algoritmo ha convergido. La convergencia se logra si las actualizaciones son menores que 'tolerance'
    if abs(alpha * costo_m) < tolerance and abs(alpha * costo_b) < tolerance:
        break

    # Imprimir los valores actuales de 'm' y 'b' cada 500 iteraciones para seguimiento
    if epoch % 500 == 0:
        print(f"Época {epoch+1}, m: {m}, b: {b}")

# Imprimir la pendiente y el intercepto finales
print(f"Pendiente: {m}")
print(f"Intercepción: {b}\n")

# RESULTADOS DE ENTRENAMIENTO

# Clasificación en el conjunto de entrenamiento
# Clasificar si un dato tiene más de 220 calorías ('Si') o menos ('No') basado en la predicción de la línea de regresión
predicciones_train = m * x_train + b
clasificacion_Cal_train = np.where(y_train > predicciones_train, 'Si', 'No')

# Generar la matriz de confusión para los datos de entrenamiento
cm_train = confusion_matrix(Cal_train, clasificacion_Cal_train, labels=['Si', 'No'])
disp_train = ConfusionMatrixDisplay(confusion_matrix=cm_train, display_labels=['220+', '220-'])

# Mostrar visualmente la matriz de confusión para los datos de entrenamiento
disp_train.plot(cmap=plt.cm.Reds)
plt.title("Entrenamiento")
plt.show()

# Calcular las métricas de evaluación en el conjunto de entrenamiento
precision = precision_score(Cal_train, clasificacion_Cal_train, pos_label='Si')
recall = recall_score(Cal_train, clasificacion_Cal_train, pos_label='Si')
f1 = f1_score(Cal_train, clasificacion_Cal_train, pos_label='Si')

# Mostrar las métricas de evaluación
print(f"Precisión: {precision:.2f}")
print(f"Recall: {recall:.2f}")
print(f"F1 Score: {f1:.2f} \n")

# Graficar los puntos de datos del conjunto de entrenamiento junto con la línea de regresión
plt.figure(figsize=(10, 6))

# Puntos de datos clasificados originalmente como con más de 220 calorías ('Si') y menos de 220 calorías ('No')
plt.scatter(x_train[Cal_train == 'Si'], y_train[Cal_train == 'Si'], color='Green', label='220+ True')
plt.scatter(x_train[Cal_train == 'No'], y_train[Cal_train == 'No'], color='Red', label='220- True')

# Puntos de datos clasificados según la nueva clasificación basada en la línea de regresión
plt.scatter(x_train[clasificacion_Cal_train == 'Si'], y_train[clasificacion_Cal_train == 'Si'], color='white', marker='.', label='220+ Predict')
plt.scatter(x_train[clasificacion_Cal_train == 'No'], y_train[clasificacion_Cal_train == 'No'], color='black', marker='.', label='220- Predict')

# Línea de regresión ajustada
plt.plot(x_train, predicciones_train, color='pink', label='Línea de regresión')

# Etiquetas y título del gráfico
plt.xlabel('Calories from Fat')
plt.ylabel('Saturated Fat')
plt.title('Regresión Lineal - Entrenamiento')
plt.legend()
plt.grid(True)
plt.show()

#Calcular aciertos y fallos para los datos de entrenamiento
train_aciertos = cm_train[0, 0] + cm_train[1, 1]  # Verdaderos positivos y verdaderos negativos
train_fallos = cm_train[0, 1] + cm_train[1, 0]  # Falsos positivos y falsos negativos

print(f"Aciertos en entrenamiento: {train_aciertos}")
print(f"Fallos en entrenamiento: {train_fallos}\n")

# RESULTADOS DE PRUEBA

# Probar el modelo en el conjunto de prueba
predicciones_test = m * x_test + b
clasificacion_Cal_test = np.where(y_test > predicciones_test, 'Si', 'No')

# Generar la matriz de confusión para los datos de prueba
cm_test = confusion_matrix(Cal_test, clasificacion_Cal_test, labels=['Si', 'No'])
disp_test = ConfusionMatrixDisplay(confusion_matrix=cm_test, display_labels=['220+', '220-'])

# Mostrar visualmente la matriz de confusión para los datos de prueba
disp_test.plot(cmap=plt.cm.Reds)
plt.title("Prueba")
plt.show()

# Calcular las métricas de evaluación en el conjunto de prueba
precision = precision_score(Cal_test, clasificacion_Cal_test, pos_label='Si')
recall = recall_score(Cal_test, clasificacion_Cal_test, pos_label='Si')
f1 = f1_score(Cal_test, clasificacion_Cal_test, pos_label='Si')

# Mostrar las métricas de evaluación
print(f"Precisión: {precision:.2f}")
print(f"Recall: {recall:.2f}")
print(f"F1 Score: {f1:.2f}\n")


# Graficar los puntos de datos del conjunto de prueba junto con la línea de regresión
plt.figure(figsize=(10, 6))

# Puntos de datos clasificados originalmente como con más de 220 calorías ('Si') y menos de 220 calorías ('No')
plt.scatter(x_test[Cal_test == 'Si'], y_test[Cal_test == 'Si'], color='Green', label='220+ True)')
plt.scatter(x_test[Cal_test == 'No'], y_test[Cal_test == 'No'], color='Red', label='220- True')

# Puntos de datos clasificados según la nueva clasificación basada en la línea de regresión
plt.scatter(x_test[clasificacion_Cal_test == 'Si'], y_test[clasificacion_Cal_test == 'Si'], color='white', marker='.', label='220+ Predict')
plt.scatter(x_test[clasificacion_Cal_test == 'No'], y_test[clasificacion_Cal_test == 'No'], color='black', marker='.', label='220- Predict')

# Línea de regresión ajustada
plt.plot(x_test, predicciones_test, color='pink', label='Línea de regresión')

# Etiquetas y título del gráfico
plt.xlabel('Calories from Fat')
plt.ylabel('Saturated Fat')
plt.title('Regresión Lineal - Prueba')
plt.legend()
plt.grid(True)
plt.show()
# Calcular aciertos y fallos para los datos de prueba
test_aciertos = cm_test[0, 0] + cm_test[1, 1]  # Verdaderos positivos y verdaderos negativos
test_fallos = cm_test[0, 1] + cm_test[1, 0]  # Falsos positivos y falsos negativos

print(f"Aciertos en prueba: {test_aciertos}")
print(f"Fallos en prueba: {test_fallos}\n")